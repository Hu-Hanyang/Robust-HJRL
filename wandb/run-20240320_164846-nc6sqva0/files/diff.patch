diff --git a/learn_distb_cleanrl.py b/learn_distb_cleanrl.py
index e62d0a9..3b8e4c8 100644
--- a/learn_distb_cleanrl.py
+++ b/learn_distb_cleanrl.py
@@ -65,9 +65,9 @@ class Args:
     """the level of disturbance to be applied to the drones"""
     learning_rate: float = 3e-4
     """the learning rate of the optimizer"""
-    num_envs: int = 1
+    num_envs: int = 32
     """the number of parallel game environments"""
-    num_steps: int = 2048
+    num_steps: int = 1000
     """the number of steps to run in each environment per policy rollout"""
     anneal_lr: bool = True
     """Toggle learning rate annealing for policy and value networks"""
@@ -77,7 +77,7 @@ class Args:
     """the lambda for the general advantage estimation"""
     num_minibatches: int = 32
     """the number of mini-batches"""
-    update_epochs: int = 10
+    update_epochs: int = 80
     """the K epochs to update the policy"""
     norm_adv: bool = True
     """Toggles advantages normalization"""
@@ -85,13 +85,13 @@ class Args:
     """the surrogate clipping coefficient"""
     clip_vloss: bool = True
     """Toggles whether or not to use a clipped loss for the value function, as per the paper."""
-    ent_coef: float = 0.0
+    ent_coef: float = 0.01
     """coefficient of the entropy"""
     vf_coef: float = 0.5
     """coefficient of the value function"""
     max_grad_norm: float = 0.5
     """the maximum norm for the gradient clipping"""
-    target_kl: float = None
+    target_kl: float = 0.01
     """the target KL divergence threshold"""
 
     # to be filled in runtime
@@ -345,7 +345,7 @@ if __name__ == "__main__":
         writer.add_scalar("losses/approx_kl", approx_kl.item(), global_step)
         writer.add_scalar("losses/clipfrac", np.mean(clipfracs), global_step)
         writer.add_scalar("losses/explained_variance", explained_var, global_step)
-        print("SPS:", int(global_step / (time.time() - start_time)))
+        # print("SPS:", int(global_step / (time.time() - start_time)))
         writer.add_scalar("charts/SPS", int(global_step / (time.time() - start_time)), global_step)
 
     if args.save_model:
diff --git a/traning_results_cleanrl/fixed-distb_level_0.0_40226/save-2024.03.20_14:02/tb/events.out.tfevents.1710968546.cs-mars-14.18564.0 b/traning_results_cleanrl/fixed-distb_level_0.0_40226/save-2024.03.20_14:02/tb/events.out.tfevents.1710968546.cs-mars-14.18564.0
index 3992ad0..f5f07fb 100644
Binary files a/traning_results_cleanrl/fixed-distb_level_0.0_40226/save-2024.03.20_14:02/tb/events.out.tfevents.1710968546.cs-mars-14.18564.0 and b/traning_results_cleanrl/fixed-distb_level_0.0_40226/save-2024.03.20_14:02/tb/events.out.tfevents.1710968546.cs-mars-14.18564.0 differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/best_model.zip b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/best_model.zip
index 01a5d1c..3202474 100644
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/best_model.zip and b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/best_model.zip differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/evaluations.npz b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/evaluations.npz
index 151cfc3..4635e51 100644
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/evaluations.npz and b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/evaluations.npz differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/tb/PPO_1/events.out.tfevents.1710968688.cs-mars-14.20491.0 b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/tb/PPO_1/events.out.tfevents.1710968688.cs-mars-14.20491.0
index 6cbfd59..6854003 100644
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/tb/PPO_1/events.out.tfevents.1710968688.cs-mars-14.20491.0 and b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:04/tb/PPO_1/events.out.tfevents.1710968688.cs-mars-14.20491.0 differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/best_model.zip b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/best_model.zip
deleted file mode 100644
index a416624..0000000
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/best_model.zip and /dev/null differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/evaluations.npz b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/evaluations.npz
deleted file mode 100644
index 151cfc3..0000000
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/evaluations.npz and /dev/null differ
diff --git a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/tb/PPO_1/events.out.tfevents.1710968741.cs-mars-14.20918.0 b/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/tb/PPO_1/events.out.tfevents.1710968741.cs-mars-14.20918.0
deleted file mode 100644
index 6216f07..0000000
Binary files a/traning_results_sb3/fixed-distb_level_0.0/save-2024.03.20_14:05/tb/PPO_1/events.out.tfevents.1710968741.cs-mars-14.20918.0 and /dev/null differ
diff --git a/wandb/latest-run b/wandb/latest-run
index 5e7e950..e6df0cf 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20240320_140222-q2b60ysf
\ No newline at end of file
+run-20240320_164846-nc6sqva0
\ No newline at end of file
diff --git a/wandb/run-20240320_140222-q2b60ysf/files/wandb-summary.json b/wandb/run-20240320_140222-q2b60ysf/files/wandb-summary.json
index 561733c..88f2118 100644
--- a/wandb/run-20240320_140222-q2b60ysf/files/wandb-summary.json
+++ b/wandb/run-20240320_140222-q2b60ysf/files/wandb-summary.json
@@ -1 +1 @@
-{"global_step": 41935, "_timestamp": 1710969641.299545, "_runtime": 1098.935954093933, "_step": 820, "charts/episodic_return": -200.0046844482422, "charts/episodic_length": 118.0, "charts/learning_rate": 0.0002988324558828026, "losses/value_loss": 626.6214599609375, "losses/policy_loss": -0.04252226650714874, "losses/entropy": 5.887751579284668, "losses/old_approx_kl": 0.02101132646203041, "losses/approx_kl": 0.00788806937634945, "losses/clipfrac": 0.078369140625, "losses/explained_variance": 0.0024265646934509277, "charts/SPS": 38.0}
\ No newline at end of file
+{"global_step": 468955, "_timestamp": 1710978523.9019034, "_runtime": 9981.53831243515, "_step": 4856, "charts/episodic_return": -159.33392333984375, "charts/episodic_length": 95.0, "charts/learning_rate": 0.00028605081024579704, "losses/value_loss": 21.754085540771484, "losses/policy_loss": -0.029462166130542755, "losses/entropy": 6.938776016235352, "losses/old_approx_kl": 0.052090227603912354, "losses/approx_kl": 0.019059844315052032, "losses/clipfrac": 0.14833983778953552, "losses/explained_variance": 0.8955294489860535, "charts/SPS": 46.0}
\ No newline at end of file
diff --git a/wandb/run-20240320_140222-q2b60ysf/run-q2b60ysf.wandb b/wandb/run-20240320_140222-q2b60ysf/run-q2b60ysf.wandb
index 36cc486..dccb96a 100644
Binary files a/wandb/run-20240320_140222-q2b60ysf/run-q2b60ysf.wandb and b/wandb/run-20240320_140222-q2b60ysf/run-q2b60ysf.wandb differ
